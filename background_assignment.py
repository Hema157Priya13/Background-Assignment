# -*- coding: utf-8 -*-
"""Background Assignment

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E3nzhkYdsCq-vJYTGIzFeYugTeVzlUb-

### Install and import required libraries and models
"""

!pip install -qq -U diffusers==0.11.1 transformers ftfy gradio accelerate
!pip install ultralytics -q

import inspect
from typing import List, Optional, Union
import numpy as np
import torch
import PIL
from diffusers import StableDiffusionInpaintPipeline

from ultralytics import YOLO

import requests
from io import BytesIO
from google.colab import drive
drive.mount('/content/drive')
import shutil
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
import os
from PIL import Image
import matplotlib.pyplot as plt

"""### Loading the stable diffusion inpainting and YOLO model"""

device = "cuda"
model_path = "runwayml/stable-diffusion-inpainting"

pipe = StableDiffusionInpaintPipeline.from_pretrained(
    model_path,
    torch_dtype=torch.float16,
).to(device)

model = YOLO("yolov8m-seg.pt")

"""### **Task 1**:
*   Input : Image with white background
*   Output : Generate a text-conditioned scene with the image placed naturally in the scene.



"""

# This folder in Google Drive contains the example images

folder_path = "/content/drive/MyDrive/examples"

# Function to save the mask image to the examples folder

def save_mask_image(mask_image, number):
  # Convert NumPy array to PIL image
  image = Image.fromarray(mask_image)

  # Save the image to Google Drive
  image_path = os.path.join(folder_path, f'mask{number}.png')
  image.save(image_path)
  return image_path

# Function to crop the mask image

def crop_to_black_pixels(image_path):
    # Open the image
    image = Image.open(image_path)
    width, height = image.size

    # Bounding box coordinates
    min_x = width
    min_y = height
    max_x = 0
    max_y = 0

    for x in range(width):
        for y in range(height):

            # Check if the pixel is black
            if image.getpixel((x, y)) == 0:

                # Update bounding box coordinates
                min_x = min(min_x, x)
                min_y = min(min_y, y)
                max_x = max(max_x, x)
                max_y = max(max_y, y)

    # Crop the image using the bounding box coordinates
    cropped_image = image.crop((min_x, min_y, max_x+1, max_y+1))

    return cropped_image, min_x, min_y, max_x+1, max_y+1

# Function to resize image and mask

def resize_image(mask_image, target_size, img):
  width, height = mask_image.size

  # Calculate scaling factor for width and height
  width_ratio = target_size[0] / width
  height_ratio = target_size[1] / height

  # Use the smaller scaling factor to fit image to target_size
  scale_factor = min(width_ratio, height_ratio)

  # Calculate the new size
  new_width = int(width * scale_factor)
  new_height = int(height * scale_factor)

  # Resize the image
  resized_image = img.resize((new_width, new_height), Image.ANTIALIAS)
  resized_mask_image = mask_image.resize((new_width, new_height), Image.ANTIALIAS)
  print(resized_image.size)

  # Create a blank white background image of target size
  background = Image.new('RGB', target_size, (255, 255, 255))
  background_mask = Image.new('RGB', target_size, (255, 255, 255))

  # Paste the resized image onto the background to keep the aspect ratio intact
  offset = ((target_size[0] - new_width) // 2, (target_size[1] - new_height) // 2)
  background.paste(resized_image, offset)
  background_mask.paste(resized_mask_image, offset)
  print('Background_mask_size', background_mask.size)
  return background, background_mask

def extend_image(mask_image, target_size, img, extension_size, shift_amount):
  background, background_mask = resize_image(mask_image, (256,256), img)

  # White background
  extension_color = (255, 255, 255)

  w, h = background_mask.size
  # Create a new image with extended dimensions
  extended_width = w + 2 * extension_size
  extended_height = h + 2 * extension_size
  paste_position = (extension_size+shift_amount, extension_size)
  extended_image = Image.new('RGB', (extended_width, extended_height), extension_color)
  extended_mask_image = Image.new('RGB', (extended_width, extended_height), extension_color)
  extended_image.paste(background, paste_position)
  extended_mask_image.paste(background_mask, paste_position)

  resize_512, resize_mask_512 = resize_image(extended_mask_image, (512,512), extended_image)
  return resize_512, resize_mask_512

# Function to display the input image and output

def image_grid(imgs, rows, cols):
    fig, axes = plt.subplots(1, cols, figsize=(cols*4, rows*4))
    for i, ax in enumerate(axes.flat):
        ax.imshow(images[i])
        ax.axis('off')  # Hide axis
    plt.show()

# It generates output for all the examples and save them in Google Drive

for i in range(1,6):
  img_name = f'example{i}.jpg'
  img_url = os.path.join(folder_path, img_name)

  # mask generation for image
  predict = model.predict(img_url , save = True , save_txt = True)
  print(len(predict))
  print(predict[0].masks.data[0].unique())

  # predict[0].masks.data[0] is the required tensor to generate mask
  tensor_on_cpu = predict[0].masks.data[0].cpu().numpy()
  numpy_array = (tensor_on_cpu * 255).astype("uint8")
  cv2_imshow(numpy_array)

  mask_image = 255-numpy_array  # converting the white mask of object to black such that it does not change
  cv2_imshow(mask_image)
  mask_url= save_mask_image(mask_image, i)

  # Crop the mask and image
  cropped_mask_image, min_x, min_y, max_x, max_y = crop_to_black_pixels(mask_url)
  cropped_mask_image.save("cropped_mask_img.png")
  image = Image.open(img_url)
  print("Original Image size", image.size)
  cropped_image = image.crop((min_x, min_y, max_x+1, max_y+1))
  cropped_image.save("cropped_img.png")
  print("Cropped image size",cropped_mask_image.size)

  # Extend the background of the image and mask
  mask_image = Image.open('cropped_mask_img.png')
  image = Image.open('cropped_img.png')
  ext_image, ext_mask_image = extend_image(mask_image, (256,256), image, 100, 0)
  print("Extended Image size",ext_image.size)

  image = ext_image.resize((512, 512))
  mask_image = ext_mask_image.resize((512, 512))
  cv2_imshow(np.array(image))
  cv2_imshow(np.array(mask_image))

  # Generates the image with text-conditioned background
  guidance_scale=7.5
  num_samples = 1
  generator = torch.Generator(device="cuda").manual_seed(1) # change the seed to get different results
  prompt= input("Enter the prompt : ")
  images = pipe(
    prompt=prompt,
    image=image,
    mask_image=mask_image,
    guidance_scale=guidance_scale,
    generator=generator,
    num_images_per_prompt=num_samples,
  ).images

  # insert initial image in the list so we can compare side by side
  images.insert(0, image)
  image_grid(images, 1, num_samples + 1)

  output_filename = f"generated_image{i}.png"  # You can change the filename and extension as per your requirement
  file_path = os.path.join(folder_path, output_filename)
  images[-1].save(file_path)

"""### **Task 2 :**



*   A small video output by generating multiple
frames
*   Zooming out of the scene gradually


"""

# Function to crop the image
def crop(img, x, y, w, h):
    x0, y0 = max(0, x-w//2), max(0, y-h//2)
    x1, y1 = x0+w, y0+h
    return img[y0:y1, x0:x1]

video_dim = (512, 512)
fps = 30
duration = 5.0
start_center = (0.3, 0.3)
end_center = (0.5, 0.5)
start_scale = 0.7
end_scale = 1.0
num_frames = int(fps * duration)

for i in range(1,6):
  img_name = f"generated_image{i}.png"
  img_url = os.path.join(folder_path, img_name)
  img = cv2.imread(img_url, cv2.IMREAD_COLOR)
  orig_shape = img.shape[:2]

  frames = []
  for alpha in np.linspace(0, 1, num_frames):
      rx = end_center[0]*alpha + start_center[0]*(1-alpha)
      ry = end_center[1]*alpha + start_center[1]*(1-alpha)
      x = int(orig_shape[1]*rx)
      y = int(orig_shape[0]*ry)
      scale = end_scale*alpha + start_scale*(1-alpha)

      # Crop based on the aspect ratio of width/height
      if orig_shape[1]/orig_shape[0] > video_dim[0]/video_dim[1]:
          h = int(orig_shape[0]*scale)
          w = int(h * video_dim[0] / video_dim[1])
      else:
          w = int(orig_shape[1]*scale)
          h = int(w * video_dim[1] / video_dim[0])

      # Crop, scale to video size and save the frame
      cropped = crop(img, x, y, w, h)
      scaled = cv2.resize(cropped, dsize=video_dim, interpolation=cv2.INTER_LINEAR)
      frames.append(scaled)

  # Write to MP4 file
  vidwriter = cv2.VideoWriter("output.mp4", cv2.VideoWriter_fourcc(*"mp4v"), fps, video_dim)
  for frame in frames:
      vidwriter.write(frame)
  vidwriter.release()

  # Save the video to Google Drive
  output_filename = f"video{i}.mp4"
  source_path = "output.mp4"
  destination_path = "/content/drive/My Drive/examples" + output_filename
  shutil.move(source_path, destination_path)